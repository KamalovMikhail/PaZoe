{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy as sc\n",
    "from scipy.sparse.linalg import gmres \n",
    "import timeit\n",
    "from sklearn import metrics  as m\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import plotly.graph_objects as go\n",
    "import plotly \n",
    "from plotly.subplots import make_subplots \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Processing WII/UWave datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MII = pd.read_csv('data/UWaveGestureLibraryX_TRAIN.txt',header = None)#  AllGestureWiimoteZ_TRAIN  \n",
    "X_MII = pd.read_csv('data/UWaveGestureLibraryX_TRAIN.txt',header = None)\n",
    "Y_MII = pd.read_csv('data/UWaveGestureLibraryX_TRAIN.txt',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MIIT = pd.read_csv('data/UWaveGestureLibraryX_TEST.txt',header = None)#  AllGestureWiimoteZ_TEST \n",
    "X_MIIT = pd.read_csv('data/UWaveGestureLibraryX_TEST.txt',header = None)\n",
    "Y_MIIT = pd.read_csv('data/UWaveGestureLibraryX_TEST.txt',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_ALL = pd.concat([Z_MII,Z_MIIT])\n",
    "X_ALL = pd.concat([X_MII,X_MIIT])\n",
    "Y_ALL = pd.concat([Y_MII,Y_MIIT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_ALL = Z_ALL.reset_index().drop(columns=['index'])\n",
    "X_ALL = X_ALL.reset_index().drop(columns=['index'])\n",
    "Y_ALL = Y_ALL.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_ALL = Z_ALL[0].values\n",
    "X_ALL = X_ALL[0].values\n",
    "Y_ALL = Y_ALL[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all = [Z_ALL, X_ALL, Y_ALL]\n",
    "list_ready = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ALL_ in list_all:\n",
    "    Y_general = []\n",
    "    for i in ALL_:\n",
    "        Y_row = []\n",
    "        for i in i.strip().split(\" \"):\n",
    "            if i != '': \n",
    "                Y_row.append(float(i)) \n",
    "        Y_general.append(Y_row)\n",
    "    list_ready.append(np.array(Y_general))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = pd.DataFrame(list_ready[0] )\n",
    "df_x = pd.DataFrame(list_ready[1] )\n",
    "df_y = pd.DataFrame(list_ready[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = df_z[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_z.drop(columns=[0])\n",
    "df_x = df_x.drop(columns=[0])\n",
    "df_y = df_y.drop(columns=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_z[np.arange(1, df_z.count(axis=1).max()+1)]\n",
    "df_x = df_x[np.arange(1, df_z.count(axis=1).max()+1)]\n",
    "df_y = df_y[np.arange(1, df_z.count(axis=1).max()+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_z.fillna(value=0)\n",
    "df_x = df_x.fillna(value=0)\n",
    "df_y = df_y.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate([df_z.values, df_x.values, df_y.values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = y_train_all - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ = np.copy(y_train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transforming data into graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adj(X_array, nnodes, metric='minkowski', n_neighbours=25):\n",
    "    Af = np.zeros((nnodes, nnodes))\n",
    "    for feature in X_array:\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbours, metric=metric ).fit(feature)\n",
    "        distances, indices = nbrs.kneighbors(feature)\n",
    "        for i in range(nnodes):\n",
    "            Af[i, indices[i]] = 1\n",
    "            Af[indices[i], i ] = 1\n",
    "    return Af "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_A_hat(adj_matrix: sp.spmatrix, delta, sigma, MMx) -> sp.spmatrix:\n",
    "    nnodes = adj_matrix.shape[0]\n",
    "    A = adj_matrix + sp.eye(nnodes)#Î©#@ D_invsqrt_corr\n",
    "    D_vec = np.sum(A, axis=1).A1 \n",
    "    lsigma = sigma - 1\n",
    "    rsigma = - sigma\n",
    "    wsigma = -2*sigma + 1\n",
    "    \n",
    "    D_l = sp.diags(np.power(D_vec, lsigma)) \n",
    "    D_r= sp.diags(np.power(D_vec, rsigma ) )\n",
    "    Dw = sp.diags(np.power(D_vec, wsigma ) )\n",
    "    S_ = MMx@ Dw \n",
    "    \n",
    "    return S_ , D_l@A@D_r  - delta* S_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. optimization parts for PRPCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IP(A, Z, Y, iter_,  alpha):\n",
    "    A = np.copy(A)\n",
    "    Z = np.copy(Z)\n",
    "    Y = np.copy(Y) \n",
    "    start = timeit.default_timer()\n",
    "    for _ in range(iter_):\n",
    "        Z =  alpha * AHAT@Z   + (1-alpha) * Y\n",
    "        Z = normalize(Z,'l1')\n",
    "    print('time(s):', timeit.default_timer() - start)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMRES(A, Y, alpha, k, tol):\n",
    "    A = np.copy(A)\n",
    "    Y = np.copy(Y) \n",
    "    predicts = []\n",
    "    for j in range(k): \n",
    "        temp_ = gmres(A, (1-alpha)*Y[:,j], tol=tol)[0] \n",
    "        predicts.append([temp_])\n",
    "    return np.concatenate(predicts).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Computation of PRPCA, PaSVM and PaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_values prpca 0.6967396158999554\n",
      "all_values prlg 0.6287202380952381\n",
      "all_values prsvc 0.6949404761904762\n",
      "all_values prpca 0.6967396158999554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhail/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_list = [[df_x.values, df_y.values, df_z.values] ]\n",
    "names = ['all_values'] \n",
    "         \n",
    "seed = 0\n",
    "sigma = 1\n",
    "nl= 20\n",
    "alpha= 0.9  \n",
    "iter_ = 10\n",
    "tol = 1e-03 \n",
    "delta = 1e-03\n",
    "beta = 0.9 \n",
    "Z_collect = []\n",
    "nnodes = X_all.shape[0]\n",
    "for ind_, X in enumerate(X_list):\n",
    "    mean_acc_prpca = []\n",
    "    mean_acc_svm = []\n",
    "    mean_acc_lr = []\n",
    "    for seed in np.arange(1): \n",
    "        Xall = np.concatenate(X, axis=1) \n",
    "        MMx = np.zeros((nnodes, nnodes))\n",
    "        nnodes = Xall.shape[0] \n",
    "        w1 = 0.001/len(X) \n",
    "        # covariance for each sensor space\n",
    "        for x in X:\n",
    "            Xn = np.copy(x) \n",
    "            Xn = Xn - np.median(Xn, axis=0)\n",
    "            S =  np.dot(Xn, Xn.T) / (Xn.shape[0] - 1 )\n",
    "            MMx +=  w1*S \n",
    "        # adjacency matrix for each sensor space\n",
    "        Af = generate_adj(X, nnodes, n_neighbours=25, metric='euclidean' )\n",
    "        mmc, AHAT = calc_A_hat(Af,  delta, sigma, MMx ) \n",
    "        rex = (np.identity(nnodes)  - alpha * AHAT )\n",
    "        # random split dataset for training\n",
    "        rs = np.random.RandomState(seed=seed) \n",
    "        ind0lab = rs.choice(np.where(Y_ == 0 )[0], nl, replace=False)\n",
    "        ind1lab = rs.choice(np.where(Y_ == 1 )[0], nl, replace=False)\n",
    "        ind2lab = rs.choice(np.where(Y_ == 2 )[0], nl, replace=False)\n",
    "        ind3lab = rs.choice(np.where(Y_ == 3 )[0], nl, replace=False)\n",
    "        ind4lab = rs.choice(np.where(Y_ == 4 )[0], nl, replace=False) \n",
    "        ind5lab = rs.choice(np.where(Y_ == 5 )[0], nl, replace=False) \n",
    "        ind6lab = rs.choice(np.where(Y_ == 6 )[0], nl, replace=False)\n",
    "        ind7lab = rs.choice(np.where(Y_ == 7 )[0], nl, replace=False) \n",
    "        all_lab = np.concatenate([ ind0lab, ind1lab, ind2lab, ind3lab,  ind4lab, ind5lab,\n",
    "                         ind6lab, ind7lab ]) \n",
    "        y_train = np.zeros((X_all.shape[0], 8)) \n",
    "        for i in all_lab:\n",
    "            y_train[i, int(Y_[i])] =  1  \n",
    "        # PPRPCA training\n",
    "        Z = GMRES(A=rex, Y=y_train, alpha=alpha, k=y_train.shape[1], tol=tol) \n",
    "        # training of PaSVM and PaLR\n",
    "        X_glob = np.concatenate([Xall, Z],axis=-1 )\n",
    "        Z_glob = np.argmax(Z , axis=-1)\n",
    "        mean_acc_prpca.append(m.accuracy_score(Y_  , np.argmax(np.array(Z), axis=1)   ))  \n",
    "        # PRPCA self-labelling\n",
    "        X_train, X_test, z_train, z_test = train_test_split(X_glob, Z_glob, test_size=0.3, random_state=1) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_glob, Y_, test_size=0.3, random_state=1) \n",
    "        # PaSVM\n",
    "        svc = SVC(gamma='auto')\n",
    "        svc.fit( X_train, z_train)\n",
    "        scv_predict = svc.predict( X_test)\n",
    "        mean_acc_svm.append(m.accuracy_score(y_test, scv_predict)) \n",
    "        # PaLR\n",
    "        clf = LogisticRegression(random_state=0) \n",
    "        clf.fit(X_train, z_train)\n",
    "        scv_predict = clf.predict(X_test)\n",
    "        mean_acc_lr.append(m.accuracy_score(y_test, scv_predict))\n",
    "    print(names[ind_], 'prlg', np.mean(mean_acc_lr)) \n",
    "    print(names[ind_], 'prsvc', np.mean(mean_acc_svm)) \n",
    "    print(names[ind_], 'prpca', np.mean(mean_acc_prpca)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computation of LP, KNN, SVM and LR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 0.5895489057615007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhail/opt/anaconda3/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:277: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/Users/mikhail/opt/anaconda3/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:288: ConvergenceWarning:\n",
      "\n",
      "max_iter=1000 was reached without convergence.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp 0.12483251451540867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhail/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg 0.5587315765966949\n",
      "svm 0.6873604287628405\n"
     ]
    }
   ],
   "source": [
    "nl = 20\n",
    "nnodes = X_all.shape[0]\n",
    "rs = np.random.RandomState(seed=0) \n",
    "ind0lab = rs.choice(np.where(Y_ == 0 )[0], nl, replace=False)\n",
    "ind1lab = rs.choice(np.where(Y_ == 1 )[0], nl, replace=False)\n",
    "ind2lab = rs.choice(np.where(Y_ == 2 )[0], nl, replace=False)\n",
    "ind3lab = rs.choice(np.where(Y_ == 3 )[0], nl, replace=False)\n",
    "ind4lab = rs.choice(np.where(Y_ == 4 )[0], nl, replace=False) \n",
    "ind5lab = rs.choice(np.where(Y_ == 5 )[0], nl, replace=False) \n",
    "ind6lab = rs.choice(np.where(Y_ == 6 )[0], nl, replace=False)\n",
    "ind7lab = rs.choice(np.where(Y_ == 7 )[0], nl, replace=False) \n",
    "all_lab = np.concatenate([ ind0lab, ind1lab, ind2lab, ind3lab,  ind4lab, ind5lab, ind6lab, ind7lab, ]) \n",
    "y_train = np.zeros((X_all.shape[0], 8)) \n",
    "for i in all_lab:\n",
    "    y_train[i, int(Y_[i])] =  1 \n",
    "    \n",
    "neigh = KNeighborsClassifier(n_neighbors=25, metric='euclidean')\n",
    "neigh.fit(X_all[all_lab], Y_[all_lab])\n",
    "yknn_predict = neigh.predict(X_all)\n",
    "print('knn', m.accuracy_score(Y_, yknn_predict))\n",
    "y_lp = np.ones(nnodes)*-1\n",
    "y_lp[all_lab] = Y_[all_lab]\n",
    " \n",
    "lp = LabelPropagation(kernel='rbf', gamma=2, n_neighbors=25)\n",
    "lp.fit(X_all, y_lp)\n",
    "yLp_predict = lp.predict(X_all)\n",
    "print('lp',m.accuracy_score(Y_, yLp_predict) )\n",
    " \n",
    "clf = LogisticRegression(random_state=0) \n",
    "clf.fit(X_all[all_lab], Y_[all_lab])\n",
    "scv_predict = clf.predict(X_all)\n",
    "print('lg',m.accuracy_score(Y_, scv_predict) )\n",
    " \n",
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_all[all_lab], Y_[all_lab])\n",
    "scv_predict = svc.predict(X_all)\n",
    "print('svm',m.accuracy_score(Y_, scv_predict) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
